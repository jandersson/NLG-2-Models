\documentclass[ai15_group61_report.tex]{subfiles}
\begin{document}

In general, according to \cite{Reiter:2000:BNL:331955}, NLG systems are constructed after performing requirements analysis whereby the goals of the NLG system are defined. Varied requirements have produced several different NLG systems over the years. Indeed, the project team designed the two NLG approaches after performing such a requirements analysis. Again \cite{Reiter:2000:BNL:331955} explains that one approach to generating text is not through NLG, rather by a technique known as mail-merge whereby a template is created and the appropriate data is filled in. In designing the experiment for the "Inferred Grammar" model, an approach similar to mail-merge was carried out.

In \cite{Ratnaparkhi00} three methods for text generation are examined. One of the models examined makes use of n-gram models. The paper explores methods for making use of the observed usage of the language in a corpus, but without manually constructing a grammar. A generation of attribute templates was the novel approach by \cite{Ratnaparkhi00} where a sequence of placeholders is constructed. The placeholders are then filled in by the three proposed models. This idea inspired the inferred grammar approach and the structure of this project whereby two models are explored.

Several textbooks explore the topic of language modelling using n-grams and part of speech tags. Works such as \cite{Jurafsky2000}, \cite{RussellNorvigAIBook3rd}, and \cite{Chen98anempirical} provide excellent tutorials to language modelling and were used extensively in this project. A discussion of n-gram order by \cite{RussellNorvigAIBook3rd} demonstrates that unigrams are a poor representation of the english language and that bigrams and trigrams provide better approximations. Unigrams perform poorly due to the loss of any ordering based on previous words or tokens \cite{RussellNorvigAIBook3rd}. An error in our experiment construction led to the inferred grammar model behaving similarly to this bag of words model.

The Natural Language Tool Kit (NLTK) boosted development productivity through a suite of tools such as probability distribution classes, n-gram decomposition functions, corpora and corpora importing utilities, and speech tagging. We extensively referenced \cite{NLTKBook09} for guidance in use of the NLTK. 

Continuing on the topic of tutorials; the study of smoothing techniques, perplexity, and n-gram models provided by \cite{Jurafsky2000} were referenced in verifying the output produced by our text generation techniques. For example, our output produced by quadgram models were suspiciously close to human authored text. Indeed, \cite{Jurafsky2000} states that the N-gram probability matrices become sparse as order increases, diminishing the set of possible continuations to approximately one. This effectively generates sentences which are found verbatim in the corpus. As such, the discussion in \cite{Jurafsky2000} led to our decision to implement trigram models. 

%Further, perplexity scores are a quantitative correlation to readability, writes Jurafsky et al.  

Smoothing has been shown, empirically, to improve the prediction accuracy of N-gram models by \cite{chen-smoothing}. By making the distributions within the N-gram model more uniform, pushing down high probabilitities and increasing low, the model can account for zero probabilities. It is further argued by \cite{chen-smoothing} that Add-One or Laplace smoothing performs poorly, due to shaving off too much probability from the higher count N-grams.  

\end{document} 