\documentclass[ai15_group61_report.tex]{subfiles}
\begin{document}

In general, according to \cite{Reiter:2000:BNL:331955}, NLG systems are constructed after performing requirements analysis whereby the goals of the NLG system are defined. Indeed, the project team designed the two NLG approaches after performing such a requirements analysis. The derived motivation is to use a data-driven approach to generating sentences using grammatical rules without manually writing said rules. This approach is similar to \cite{Ratnaparkhi00}.

Language models are a staple in many domains including speech recognition, optical character recognition, handwriting recognition, machine translation, and spelling correction. The dominant technology in language modeling is n-gram models, which are straightforward to construct except for the issue of smoothing, a technique used to better estimate probabilities when there is insufficient data to estimate probabilities accurately\cite{chen-smoothing}. Many different techniques have been proposed for smoothing n-gram models. In this project we show how different smoothing techniques work and how they will affect the sentences generated.

\end{document}